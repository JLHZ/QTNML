{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simplifed_MPS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ec_krmLUgK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c1589aa3-d8e1-4055-a6cc-5977470a3b75"
      },
      "source": [
        "pip install tensornetwork"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensornetwork\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/e9/8575b2a9bdf634258b64e581014117f1c8386fd55c2bc84e6624ba747916/tensornetwork-0.4.1-py3-none-any.whl (295kB)\n",
            "\r\u001b[K     |█                               | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.6/dist-packages (from tensornetwork) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from tensornetwork) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensornetwork) (3.3.0)\n",
            "Collecting graphviz>=0.11.1\n",
            "  Downloading https://files.pythonhosted.org/packages/62/dc/9dd6a6b9b8977248e165e075b109eea6e8eac71faa28ca378c3d98e54fbe/graphviz-0.14.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.6/dist-packages (from tensornetwork) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py>=2.9.0->tensornetwork) (1.15.0)\n",
            "Installing collected packages: graphviz, tensornetwork\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.14.1 tensornetwork-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgwkSBNKLgcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "# Import tensornetwork\n",
        "import tensornetwork as tn\n",
        "# Set the backend to tesorflow\n",
        "# (default is numpy)\n",
        "tn.set_default_backend(\"tensorflow\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VivQwBoJLmGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class MPSLayer(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, rank, bond, feature, label_size, dtype=tf.float32):\n",
        "    super(MPSLayer, self).__init__()\n",
        "    self.label_site = rank // 2\n",
        "    # Create the variables for the layer.\n",
        "    # self.l_region = tf.Variable(tf.random.normal(\n",
        "    #         shape=(self.label_site, feature, bond, bond)),\n",
        "    #          name=\"left\", trainable=True)\n",
        "    # self.r_region = tf.Variable(tf.random.normal(\n",
        "    #         shape=(rank - self.label_site, feature, bond, bond)),\n",
        "    #          name=\"right\", trainable=True)\n",
        "    # self.output_site = tf.Variable(tf.random.normal(\n",
        "    #         shape=(bond, label_size, bond)),\n",
        "    #          name=\"output\", trainable=True)\n",
        "    self.l_region = tf.Variable(self._initializer(self.label_site, feature, bond),\n",
        "                            dtype=dtype, trainable=True)\n",
        "    self.r_region = tf.Variable(self._initializer(self.label_site, feature, bond),\n",
        "                             dtype=dtype, trainable=True)\n",
        "    self.output_site = tf.Variable(self._initializer(label_size, 1, bond)[0],\n",
        "                              dtype=dtype, trainable=True)\n",
        "    \n",
        "  @staticmethod\n",
        "  def _initializer(n_sites, d_phys, d_bond):\n",
        "    w = np.stack(d_phys * n_sites * [np.eye(d_bond)])\n",
        "    w = w.reshape((d_phys, n_sites, d_bond, d_bond))\n",
        "    return w + np.random.normal(0, 1e-2, size=w.shape)\n",
        "\n",
        "  def call(self, input_x):\n",
        "    # Define the contraction.\n",
        "    # We break it out so we can parallelize a batch using\n",
        "    # tf.vectorized_map (see below).\n",
        "    \n",
        "    # input_x shape in [b,rank,2]\n",
        "    left = tf.einsum(\"fsij,bsf->sbij\", self.l_region, input_x[:,:self.label_site])\n",
        "    right = tf.einsum(\"fsij,bsf->sbij\", self.r_region, input_x[:,self.label_site:])\n",
        "    left = self.reduction(left)\n",
        "    right = self.reduction(right)\n",
        "    return tf.einsum(\"bij,jok,bki->bo\", left, self.output_site, right)\n",
        "    # Now we create the network.\n",
        "    # l_core = tn.Node(self.l_region) # [s,i,f,j]\n",
        "    # r_core = tn.Node(self.r_region) # [s,j,f,j]\n",
        "    # output_core = tn.Node(self.output) # [i,o,j]\n",
        "    # x_l = tn.Node(x[:self.label_site])  # [s,f]\n",
        "    # x_r = tn.Node(x[self.label_site:])  # [s,f]\n",
        "\n",
        "    # The TN should now look like this\n",
        "    #      |    |.   |\n",
        "    # >--- a -- c -- b ---<\n",
        "    #      |         |  \n",
        "    #.    x1.        x2\n",
        "    # Now we begin the contraction.\n",
        "\n",
        "  @staticmethod\n",
        "  def reduction(tensor):\n",
        "    size = int(tensor.shape[0])\n",
        "    while size > 1:\n",
        "      half_size = size // 2\n",
        "      nice_size = 2 * half_size\n",
        "      leftover = tensor[nice_size:]\n",
        "      tensor = tf.matmul(tensor[0:nice_size:2], tensor[1:nice_size:2])\n",
        "      tensor = tf.concat([tensor, leftover], axis=0)\n",
        "      size = half_size + int(size % 2 == 1)\n",
        "    return tensor[0]\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH6Jaw4UUfbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Model\n",
        "bond_dim = 10\n",
        "feature = 2\n",
        "rank = 28**2\n",
        "label_size = 10\n",
        "\n",
        "mps_model = tf.keras.Sequential(\n",
        "    [\n",
        "     MPSLayer(rank=rank, bond=bond_dim, feature=feature, label_size=label_size),\n",
        "     tf.keras.layers.Softmax()\n",
        "     ])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM-q92pcdvds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data\n",
        "\n",
        "num_classes = 10\n",
        "def preprocess_images(x):\n",
        "  n_data, dim0, dim1 = tuple(x.shape)\n",
        "  n_sites = dim0 * dim1\n",
        "  x = x.reshape((n_data, n_sites)) / 255\n",
        "  x = tf.cast(tf.math.greater(x, 0.5), dtype=tf.int32)\n",
        "  return tf.keras.utils.to_categorical(x, 2)\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
        "# convert images to supported format\n",
        "x_train = preprocess_images(x_train)\n",
        "x_test = preprocess_images(x_test)\n",
        "\n",
        "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# def preprosessing(X):\n",
        "#     X = X.astype(np.float32).reshape(-1, 28**2) / 255.0\n",
        "#     return np.stack([X, 1-X], axis=2)\n",
        "\n",
        "# x_train, x_test = preprosessing(x_train), preprosessing(x_test)\n",
        "# y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "# y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# # train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "# # train_ds = train_ds.shuffle(buffer_size=2048).batch(batch_size)\n",
        "# # test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58C4V6MUUhbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33c42f6a-c965-4115-bf28-13e446d202a4"
      },
      "source": [
        "# training\n",
        "%%time\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "learning_rate = 1e-4\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "mps_model.compile(\n",
        "    loss = loss_fn,\n",
        "    optimizer = optimizer,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "mps_model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "\n",
        "score = mps_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 1.7135 - accuracy: 0.7476 - val_loss: 1.6471 - val_accuracy: 0.8126\n",
            "Epoch 2/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6405 - accuracy: 0.8203 - val_loss: 1.6306 - val_accuracy: 0.8304\n",
            "Epoch 3/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6347 - accuracy: 0.8260 - val_loss: 1.6688 - val_accuracy: 0.7914\n",
            "Epoch 4/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6321 - accuracy: 0.8286 - val_loss: 1.6173 - val_accuracy: 0.8434\n",
            "Epoch 5/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6201 - accuracy: 0.8407 - val_loss: 1.6409 - val_accuracy: 0.8204\n",
            "Epoch 6/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6194 - accuracy: 0.8415 - val_loss: 1.6223 - val_accuracy: 0.8382\n",
            "Epoch 7/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6247 - accuracy: 0.8364 - val_loss: 1.6272 - val_accuracy: 0.8335\n",
            "Epoch 8/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6300 - accuracy: 0.8308 - val_loss: 1.6212 - val_accuracy: 0.8400\n",
            "Epoch 9/30\n",
            "469/469 [==============================] - 10s 22ms/step - loss: 1.6246 - accuracy: 0.8364 - val_loss: 1.6583 - val_accuracy: 0.8025\n",
            "Epoch 10/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6171 - accuracy: 0.8440 - val_loss: 1.6102 - val_accuracy: 0.8507\n",
            "Epoch 11/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6138 - accuracy: 0.8470 - val_loss: 1.6264 - val_accuracy: 0.8340\n",
            "Epoch 12/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.6237 - accuracy: 0.8373 - val_loss: 1.6320 - val_accuracy: 0.8291\n",
            "Epoch 13/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 1.7037 - accuracy: 0.7574 - val_loss: 2.1442 - val_accuracy: 0.3167\n",
            "Epoch 14/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 2.2304 - accuracy: 0.2307 - val_loss: 2.3583 - val_accuracy: 0.1029\n",
            "Epoch 15/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 2.3572 - accuracy: 0.1039 - val_loss: 2.3583 - val_accuracy: 0.1029\n",
            "Epoch 16/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 2.3572 - accuracy: 0.1039 - val_loss: 2.3583 - val_accuracy: 0.1029\n",
            "Epoch 17/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 2.3572 - accuracy: 0.1039 - val_loss: 2.3583 - val_accuracy: 0.1029\n",
            "Epoch 18/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 2.3572 - accuracy: 0.1039 - val_loss: 2.3583 - val_accuracy: 0.1029\n",
            "Epoch 19/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 2.3572 - accuracy: 0.1039 - val_loss: 2.3583 - val_accuracy: 0.1029\n",
            "Epoch 20/30\n",
            "469/469 [==============================] - 10s 21ms/step - loss: 2.3572 - accuracy: 0.1039 - val_loss: 2.3583 - val_accuracy: 0.1029\n",
            "Epoch 21/30\n",
            "160/469 [=========>....................] - ETA: 6s - loss: 2.3576 - accuracy: 0.1035"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f9d8de5ea7e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"batch_size = 128\\nepochs = 30\\nlearning_rate = 1e-4\\n\\noptimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\\nloss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\\n\\nmps_model.compile(\\n    loss = loss_fn,\\n    optimizer = optimizer,\\n    metrics=['accuracy']\\n)\\n\\nmps_model.fit(x_train, y_train,\\n          batch_size=batch_size,\\n          epochs=epochs,\\n          verbose=1,\\n          validation_data=(x_test, y_test))\\n\\nscore = mps_model.evaluate(x_test, y_test, verbose=0)\\nprint('Test loss:', score[0])\\nprint('Test accuracy:', score[1])\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_sMkYekUksn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}